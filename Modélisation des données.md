#  Mod√©lisation des donn√©es (ER + dictionnaire PK/FK/Index)

## 1) Diagramme ER (synth√®se)

<img width="2712" height="557" alt="image" src="https://github.com/user-attachments/assets/48297354-c0e8-40d8-8582-81c9b9104ac2" />


## 2) Dictionnaire des tables (PK, FK, Index)

### USER
- **PK:** `user_id`
- **Champs:** `email UNIQUE`, `name`, `photo_url`, `preferred_lang`, `roles`, `id_verified`, `reliability_score`, `reputation`, `created_at`
- **Index:** `email UNIQUE`

### SKILL
- **PK:** `skill_id`
- **FK:** `user_id ‚Üí USER.user_id`
- **Champs:** `label`, `type {TEACH|LEARN}`, `level {BEGINNER|INTERMEDIATE|ADVANCED}`, `langs`
- **Index:** `(user_id)`, `label (TEXT)`, `(type, level)`, `(langs)`

### SESSION
- **PK:** `session_id`
- **FK:** `user_a_id ‚Üí USER`, `user_b_id ‚Üí USER`, `created_by ‚Üí USER`
- **Champs:** `start_at`, `end_at`, `mode {remote|onsite}`, `place_point` **ou** `video_url`, `status {PROPOSED|CONFIRMED|DONE|CANCELLED|NO_SHOW}`, `translated_chat (bool)`
- **Index:** `(user_a_id, user_b_id, start_at)`, `(status, start_at)`, `place_point (2D/2dsphere si g√©o)`

### MESSAGE
- **PK:** `message_id`
- **FK:** `session_id ‚Üí SESSION`, `sender_id ‚Üí USER`
- **Champs:** `text`, `lang`, `audio_url?`, `file_url?`, `translated_text?`, `created_at`
- **Index:** `(session_id, created_at)`, `(sender_id, created_at)`

### REVIEW
- **PK:** `review_id`
- **FK:** `session_id ‚Üí SESSION`, `reviewer_id ‚Üí USER`, `reviewee_id ‚Üí USER`
- **Champs:** `stars (1..5)`, `punctuality`, `pedagogy`, `engagement`, `communication`, `comment`, `created_at`
- **Contraintes:** `UNIQUE(session_id, reviewer_id)`
- **Index:** `(reviewee_id, created_at DESC)`, `(session_id)`

### GROUP
- **PK:** `group_id`
- **FK:** `admin_id ‚Üí USER`
- **Champs:** `title`, `description`, `visibility`, `created_at`
- **Index:** `(admin_id)`, `(created_at DESC)`

### GROUP_MEMBERSHIP
- **PK:** `membership_id`
- **FK:** `group_id ‚Üí GROUP`, `user_id ‚Üí USER`
- **Champs:** `role {ADMIN|COADMIN|MEMBER}`, `joined_at`
- **Contraintes:** `UNIQUE(group_id, user_id)`
- **Index:** `(group_id, user_id)`, `(joined_at)`

### TASK
- **PK:** `task_id`
- **FK:** `group_id ‚Üí GROUP`
- **Champs:** `title`, `description`, `status {TODO|IN_PROGRESS|DONE}`, `deadline`, `attachment_url?`, `created_at`
- **Index:** `(group_id, status, deadline)`

### BADGE
- **PK:** `badge_id`
- **Champs:** `code UNIQUE`, `name`, `description`, `icon`
- **Index:** `code UNIQUE`

### USER_BADGE
- **PK:** `user_badge_id`
- **FK:** `user_id ‚Üí USER`, `badge_id ‚Üí BADGE`
- **Champs:** `awarded_at`
- **Contraintes:** `UNIQUE(user_id, badge_id)`
- **Index:** `(user_id, awarded_at DESC)`

### USER_STATS
- **PK:** `user_id` (1‚Äì1 avec USER)
- **FK:** `user_id ‚Üí USER`
- **Champs:** `counters JSON/colonnes`, `updated_at`

### IDENTITY_LINK
- **PK:** `identity_link_id`
- **FK:** `user_id ‚Üí USER`
- **Champs:** `provider`, `provider_id`
- **Contraintes:** `UNIQUE(provider, provider_id)`

### PHONE_VERIF
- **PK:** `phone_verif_id`
- **FK:** `user_id ‚Üí USER`
- **Champs:** `phone`
- **Contraintes:** `UNIQUE(phone)`

### MEDIA
- **PK:** `media_id`
- **FK:** `user_id ‚Üí USER`
- **Champs:** `type {INTRO_VIDEO|IMAGE|DOC|AUDIO}`, `url`, `duration_sec?`, `mime?`, `size?`, `created_at`
- **Index:** `(user_id, created_at DESC)`, `(type, created_at DESC)`

### REPORT (signalement)
- **PK:** `report_id`
- **FK:** `reporter_id ‚Üí USER`, `reported_user_id ‚Üí USER`
- **Champs:** `target_type`, `target_id`, `reason`, `status {OPEN|IN_REVIEW|CLOSED}`, `created_at`, `updated_at`
- **Index:** `(status, created_at DESC)`, `(reported_user_id)`

### RANKING (si vous gardez la table)
- **PK:** `ranking_id`
- **FK:** `user_id ‚Üí USER`
- **Champs:** `timeframe {DAILY|WEEKLY|MONTHLY|YEARLY|ALL_TIME}`, `role {TEACHER|LEARNER}`, `score`
- **Contraintes:** `UNIQUE(user_id, timeframe, role)`
- **Index:** `(timeframe, role, score DESC)`

### NOTIFICATION_LOG (utile pour tra√ßabilit√©)
- **PK:** `notification_id`
- **FK:** `user_id ‚Üí USER`
- **Champs:** `type {push|email}`, `status {SENT|RETRY|FAILED}`, `sent_at`
- **Index:** `(user_id, sent_at DESC)`, `TTL sur sent_at (si support√©)`

---

## 3) Normalisation (r√®gles appliqu√©es)

- **1NF :** attributs atomiques, listes externalis√©es en tables d√©di√©es (ex. membres de groupe ‚Üí `GROUP_MEMBERSHIP`).
- **2NF :** pas de d√©pendances partielles d‚Äôune PK composite (on √©vite les PK composites, ou on met une cl√© technique).
- **3NF :** aucun attribut non-cl√© ne d√©pend d‚Äôun autre attribut non-cl√© (ex. `Badge` s√©par√© de `UserBadge`).

**Contraintes d‚Äôunicit√© :**
- `USER.email`, `REVIEW(session_id, reviewer_id)`,  
  `GROUP_MEMBERSHIP(group_id, user_id)`,  
  `BADGE.code`, `USER_BADGE(user_id, badge_id)`,  
  `IDENTITY_LINK(provider, provider_id)`, `PHONE_VERIF.phone`.

**Donn√©es lourdes :** fichiers/vid√©os hors base (stockage objet), `MEDIA` = m√©tadonn√©es.

**Index m√©tier :**
- recherche prof/comp√©tence (`SKILL.label` TEXT, `(type,level)`, `langs`),  
- proximit√© (`SESSION.place_point` g√©o),  
- chronologie (`MESSAGE(session_id, created_at)`),  
- r√©putation (`REVIEW(reviewee_id, created_at DESC)`).

#  SwapSkill ‚Äî **Choix de la Technique de R√©plication**


---

## 2) Choix de la Technique de R√©plication

### 2.1 Exploration des techniques (performance ‚ö° vs fiabilit√© üîí)

| Technique | Principe | Avantages | Inconv√©nients / Risques | Cas d‚Äôusage |
|---|---|---|---|---|
| **Synchrone** | Le commit est confirm√© apr√®s √©criture sur ‚â•1 r√©plique | Coh√©rence forte, **RPO ‚âà 0** | Latence ‚Üë, d√©pend r√©seau, risque de blocage | Paiements, commandes |
| **Asynchrone** | Le leader confirme localement puis r√©plique en diff√©r√© | D√©bit ‚Üë, latence ‚Üì, absorbe les pics | **RPO > 0** (perte r√©cente possible), lectures stales | Chat, flux sociaux |
| **Semi‚Äësynchrone (quorum)** | Commit apr√®s ack de *N* r√©pliques | Bon compromis coh√©rence/latence | Complexit√©, latence > asynchrone | Donn√©es critiques non financi√®res |
| **Multi‚Äëleader** | Plusieurs leaders acceptent des √©critures | Haute dispo g√©o, √©criture locale | Conflits √† r√©soudre, complexit√© | Multi‚Äër√©gions √† faible conflit |
| **Leader‚ÄìFollower** | Un leader √©crit, followers lisent | Simple, scale lecture | √âcritures limit√©es au leader | Par d√©faut (Mongo RS, Postgres) |

> **RPO** = perte de donn√©es max tol√©r√©e ; **RTO** = temps de reprise max. Plus c‚Äôest bas, mieux c‚Äôest.

---

### 2.2 D√©cision pour SwapSkill (par domaine)

#### A) Domaine social ‚Äî MongoDB (profils, skills, sessions, messages, reviews)
- **Mod√®le** : *Leader‚ÄìFollowers* (Replica Sets), √©volutif en **sharding**.
- **R√©plication** : **Asynchrone** par d√©faut.
- **Garanties cibl√©es** :
  - `messages` ‚Üí *writeConcern* `w:1` (latence prioritaire), *readConcern* `local`.
  - `sessions`, `reviews` ‚Üí `w:"majority", j:true`, *readConcern* `majority` (int√©grit√© m√©tier).
- **B√©n√©fice** : UX temps r√©el, volume √©lev√©, tout en s√©curisant les objets critiques.

#### B) Paiements/abonnements ‚Äî PostgreSQL
- **Mod√®le** : **Primaire** + **Standby synchrone** (quorum = 1) + **Standby DR asynchrone** (multi‚Äër√©gion).
- **R√©plication** : **Synchrone** (primaire ‚Üî standby AZ) + **Asynchrone** (site de secours).
- **B√©n√©fice** : **RPO ‚âà 0** localement et continuit√© d‚Äôactivit√© en cas d‚Äôincident r√©gional.

---

### 2.3 Sch√©ma de principe

<img width="658" height="992" alt="image" src="https://github.com/user-attachments/assets/6cac0d8e-550e-4943-a45d-f9a873f632f2" />


### 2.4 Impacts concrets attendus

- **Latence** : Chat P95 ‚Üì ; √©critures `sessions/reviews` ‚Üë mod√©r√©ment (majority + journalisation).
- **Fiabilit√©** : Paiements tiennent la panne d‚ÄôAZ sans perte ; Social rattrape via r√©plication diff√©r√©e.
- **Co√ªt & Complexit√©** : Contr√¥l√©e (quorum limit√© c√¥t√© PG ; write concerns cibl√©s c√¥t√© Mongo).

---

### 2.5 Param√®tres/bonnes pratiques (extraits)

**MongoDB (par collection)**  
- `messages` : `writeConcern: { w: 1 }`, `readPreference: primary` pour le flux actif.  
- `sessions`, `reviews` : `writeConcern: { w: "majority", j: true }`, `readConcern: "majority"`.

**PostgreSQL**  
- `synchronous_commit=on` ; `synchronous_standby_names='1 (pgsync1,pgsync2)'`.  
- WAL archiving + base backups pour **PITR** ; **pgbouncer/HAProxy** pour la bascule.

---

### 2.6 Synth√®se (opinion)

- **Choix** : **Asynchrone contr√¥l√©** pour le social (MongoDB) + **Synchrone** pour le financier (PostgreSQL).  
- **Raison** : maximise l‚Äô**exp√©rience temps r√©el** tout en pr√©servant la **coh√©rence critique**.  
- **Message cl√©** : **coh√©rence diff√©renci√©e** selon la sensibilit√© de la donn√©e = meilleur compromis perf/fiabilit√©.

---


#  SwapSkill ‚Äî **Configuration du Cluster ‚Äî Choix et justification**

### 3.1 Choix par domaine
- **Domaine social (MongoDB : profils, skills, sessions, messages, reviews)**  
  **Mode : Actif‚ÄìActif (sharding + replica sets)**  
  **Pourquoi :** charge d‚Äô√©criture/lecture √©lev√©e et distribu√©e, latence faible (chat), scalabilit√© horizontale, tol√©rance aux pannes par shard.

- **Paiements/abonnements (PostgreSQL)**  
  **Mode : Actif‚ÄìPassif (primaire + standby synchrone + DR asynchrone)**  
  **Pourquoi :** coh√©rence stricte (RPO‚âà0) pour les transactions, bascule contr√¥l√©e et rapide.

---

### 3.2 Topologies de r√©f√©rence

#### A) MongoDB ‚Äî Actif‚ÄìActif (sharding + replica sets)
<img width="1298" height="1048" alt="image" src="https://github.com/user-attachments/assets/f0834774-7039-4f16-a650-6b8bd5575f7e" />

* `==>|sync|` = r√©plication synchrone, `-.->|async|` = r√©plication asynchrone.

####  MongoDB ‚Äî Actif‚ÄìActif (sharding + replica sets)
- **U ‚Üí LB ‚Üí M1/M2** : les clients passent par l‚ÄôAPI/LB puis par deux routeurs *mongos*.
- **CS1‚ÄìCS3** : serveurs de config (m√©tadonn√©es du cluster). Les routeurs les consultent pour savoir o√π envoyer les requ√™tes.
- **Shard A / Shard B** : chaque shard est un **replica set** (**Primary** + **Secondaries**).
- **√âcritures** : toujours sur le **Primary** du shard concern√© (cl√© de sharding = r√©partition).
- **Lectures** : temps r√©el sur *primary* ; possibilit√© d‚Äôutiliser des *secondaries* pour du reporting.
- **Panne** : si un Primary tombe, une **√©lection** promeut un Secondary. Seul le shard touch√© est impact√©.

  
#### B) PostgreSQL ‚Äî Actif‚ÄìPassif
<img width="2037" height="970" alt="image" src="https://github.com/user-attachments/assets/030ed23e-7d24-4c1b-87b7-e64bda10fd23" />


---
* `==>|sync|` = r√©plication synchrone, `-.->|async|` = r√©plication asynchrone.

####  PostgreSQL ‚Äî Actif‚ÄìPassif (primaire + sync standby + DR)
- **APP ‚Üí pgbouncer/HAProxy ‚Üí PG1** : l‚Äôapplication se connecte via un proxy au **Primary**.
- **PG2 (sync standby)** : chaque commit est valid√© apr√®s ACK de PG2 ‚áí **RPO‚âà0** en local.
- **PGDR (async)** : r√©plique distante pour **DR** (tol√®re un l√©ger retard).
- **WAL Archive / S3** : archivage des journaux pour **PITR** (restaurations fines).
- **Panne** : le proxy bascule sur le standby promu ; l‚Äôancien primaire est r√©int√©gr√© ensuite.
### 3.3 Pourquoi ces modes sont adapt√©s

| Domaine | Mode | Besoin cl√© | Justification |
|---|---|---|---|
| Social (MongoDB) | Actif‚ÄìActif | **Latence & scalabilit√©** | Partitionnement par usage, parall√©lisme, absorption des pics chat/recherche |
| Paiements (PostgreSQL) | Actif‚ÄìPassif | **Coh√©rence & conformit√©** | Z√©ro perte locale (sync), bascule simple et testable, DR multi-r√©gion |

---

### 3.4 Comportement en fonctionnement & panne

**MongoDB (Actif‚ÄìActif)**  
- Normal : `mongos` r√©partit lectures/√©critures par shard.  
- Panne primaire : √©lection < 15 s, reroutage automatique.  
- Panne shard : d√©gradation locale, le reste du syst√®me continue.

**PostgreSQL (Actif‚ÄìPassif)**  
- Normal : commit apr√®s ack du standby synchrone (RPO‚âà0).  
- Panne primaire : promotion du standby via proxy ; r√©int√©gration ensuite.  
- Panne r√©gion : bascule pilot√©e sur DR (RPO = lag async).

---

### 3.5 Param√®tres & bonnes pratiques

**MongoDB**  
- 3 n≈ìuds data-bearing par replica set.  
- `writeConcern`: `w:1` (messages), `w:"majority", j:true` (sessions/reviews).  
- `readConcern`: `local` (temps r√©el), `majority` (critique).

**PostgreSQL**  
- `synchronous_commit=on` ; `synchronous_standby_names='1 (pgsync1,pgsync2)'`.  
- WAL archiving + backups (PITR).  
- pgbouncer/HAProxy + Patroni/pg_auto_failover.

---

### 3.6 Checklist

- Multi-AZ pour les n≈ìuds critiques.  
- Quorum garanti sur chaque replica set Mongo.  
- ‚â• 2 mongos et 3 config servers.  
- PG primaire + standby sync (AZ distinctes) + DR.  
- Runbooks : failover Mongo/PG, restauration PITR.  
- Monitoring : latence, replication lag, √©lections, erreurs WAL.

---

**Conclusion**  
- **Actif‚ÄìActif (MongoDB)** pour la partie sociale temps r√©el et scalable.  
- **Actif‚ÄìPassif (PostgreSQL)** pour s√©curiser les transactions avec **RPO‚âà0** et bascule ma√Ætris√©e.

  # ‚òÅÔ∏è Haute Disponibilit√© ‚Äî SwapSkill (Section 4)

#  SwapSkill ‚Äî **Planification de la Haute Disponibilit√©**

### 4.1 Objectifs & principes
- **RPO/RTO** cibles : MongoDB ‚â§ 5 min / 10 min ; PostgreSQL ‚âà 0 / 1‚Äì2 min.
- Multi‚ÄëAZ, r√©plication, bascule automatique, backups + **PITR**, observabilit√©, tests r√©guliers.

---

### 4.2 Gestion des failles ‚Äî Sch√©mas simples (Mermaid)

#### A) MongoDB ‚Äî Perte d‚Äôun Primary (√©lection automatique)
<img width="1262" height="421" alt="image" src="https://github.com/user-attachments/assets/0a7d6a83-2454-4fa8-a44d-e2b219cc8c21" />

 le routeur envoie au Primary ; en cas de panne, un Secondary est √©lu **Nouveau Primary** et le trafic est rerout√©.

---

#### B) MongoDB ‚Äî Perte d‚Äôun shard (d√©gradation locale)
<img width="1272" height="477" alt="image" src="https://github.com/user-attachments/assets/579408d6-9d93-4100-b4f1-e9070f12701c" />

 si **Shard A** tombe, seules les donn√©es qu‚Äôil h√©berge sont impact√©es ; le reste du syst√®me fonctionne via **Shard B**.

---

#### C) PostgreSQL ‚Äî Perte du Primary (promotion standby)
<img width="1260" height="412" alt="image" src="https://github.com/user-attachments/assets/abb9119a-4e7f-4f87-87e8-c6f6fd604369" />

 le Proxy envoie vers le Primary ; la r√©plication vers PG2 est synchrone (z√©ro perte locale), et vers PGDR asynchrone (site de secours).
---

### 4.3 Mesures cl√©s (r√©sum√©)
- **MongoDB** : replica sets (3 n≈ìuds), `writeConcern` adapt√© (w:1 vs w:"majority"), `readConcern` (local/majority), rolling upgrades.
- **PostgreSQL** : `synchronous_commit=on`, standby synchrone + DR asynchrone, WAL archiving, tests de failover et restauration.

### 4.4 Checklist
- Multi‚ÄëAZ ; quorum assur√© ; ‚â• 2 routeurs ; backups quotidiens + **PITR** ; runbooks √† jour ; monitoring lag/latence/√©lections/erreurs WAL.
